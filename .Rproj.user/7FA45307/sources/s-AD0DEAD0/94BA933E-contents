---
title: 'Mining Text from PDF Files, Part 1: PDF with Text'
author: "Antti Rask"
date: '2021-05-22'
categories: R
tags:
- pdf
- pdftools
- regex
- tidyverse
- writexl
- DataEditR
lastmod: '2021-05-22T17:02:56+03:00'
slug: mining-text-from-pdf-files-part-1-pdf-with-text
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```

# Intro

I wanted to find out how to mine text from PDF files with R. I'm experimenting with different formats, which will each have their own blog post. This first one is about PDF files with just text in them. The second one will be about extracting text in tables and in the third one I will extract text that's in a picture inside a PDF file.

I'm assuming you're using RStudio as your IDE (Integrated Development Environment). I'm sure most of this can be done with using something else as well, but I don't know how the DataEditR part, for instance, will work in another environment. 

# __pdftools__ in action

For this experiment, I'm using this cool package called [pdftools](https://docs.ropensci.org/pdftools/). I know I'm only scratching the surface here and if you'd like to know more, you should probably read the package's documentation.

## 1. Let's get ready

Before we go any further, I'm going to load the packages we'll be needing today:
```{r, warning=FALSE, message=FALSE}
library(pdftools)
# The main package for this operation

library(tidyverse)
# Prerequisite to everything

library(DataEditR)
# More about this one when we get there, but basically 'Excel in R'

library(writexl)
# My go-to package for writing Excel files
```

I'll also show you the raw material. If you'd like to try this at home, you can save the PDF file shown below. What we're looking at here is [(Spotify's weekly top 100 chart for Finland (2021-05-14 - 2021-05-21)](https://spotifycharts.com/regional/fi/weekly/2021-05-14--2021-05-21), but in text form.

As you can see, the formatting is a bit rough and (spoiler alert) it will cause us some problems along the way. Let's see how we'll be able to handle them.

![fig. 1 - The raw material](images/pdf_with_text.pdf){width=100%}

## 2. Read in the PDF file

Next, let's read in the pdf text file as a character vector using _pdf_text()_:

```{R}
pdf_with_text <- pdf_text("index_files/pdf_with_text.pdf")
pdf_with_text
```

As you can see, we got the text, but it's in six big chunks that need to be split up, before it's of any use to us. Which brings me to...

## 3. Split the character vector into a _list_

We should now create a _list_ by splitting the character vector with _strsplit_ (using those row change marks (\\ + n):

```{R}
pdf_with_text_list <- strsplit(pdf_with_text, split = "\n")

pdf_with_text_list
```

Now, that looks better already, but we're still not quite there. We want to get all the rows together.

## 4. _Unlist()_ and create a _tibble_ 

Let's start by _unlisting_ the _list_ and creating a _tibble_ (a special kind of a _data frame_):

```{R}
pdf_with_text_tbl <- as_tibble(unlist(pdf_with_text_list))

pdf_with_text_tbl
```
Nice! We now have all 196 rows together. But since it's supposed to be a top 100 chart, we can see that there are 96 extra rows that need to be taken care of. Let's next see what we can do about it.

## 5. _Filter_ out empty rows and remove first row

Let's now _filter_ out the empty rows and remove the first row with _slice()_. It does contain the column titles, so you probably want to copy them to safety first. We'll be needing them later.

```{R}
pdf_with_text_filtered_tbl <- pdf_with_text_tbl %>%
  filter(value != "") %>%
  slice(-1) # Note to self and others: slice(n) to keep the nth row, slice(-n) to get rid of it 

pdf_with_text_filtered_tbl
```

That's more like it. A hundred rows for a hundred tracks. But now for the tricky part. We know that there should be four columns, but we only see one, _value_.

## 6. _Separate_ text into columns with _regex_

This is the part that I have to start with a __HUGE DISCLAIMER__: I'm not an expert on _regex_ (regular expression). I'm pretty sure there would be a better way to do this next part. And if you are reading this and know what it is, please let me know!

As we can see from the previous tibble, Blind Channel and their song Dark Side are separated by only one empty character. If all the "columns" were separated by at least two empty characters, this would be an easy task. And since that's the closest thing to an acceptable solution, that's what we'll still do.

```{R}
pdf_with_text_separated_tbl <- pdf_with_text_filtered_tbl %>% 
  separate(col      = value,
           # col    = the column which we are separating
           
           into     = c("artist", "track", "rank", "streams"),
           # into   = the new column names
           
           sep      = "[ ]{2,}",
           # sep    = the regex pattern to separate the value column by, in this case by using two or more empty characters
           
           remove   = TRUE)
           # remove = if TRUE, removes the original value column

pdf_with_text_separated_tbl
```

As you can see, we received a _warning_ about missing pieces that were now filled with _NA_. Since I don't see a proggammable way out of this situation, we'll try to fix things using the [__DataEditR__](https://dillonhammill.github.io/DataEditR/) package. Only one quick _mutate()_ to change the rank and stream columns' types from text to numeric:

```{R}
pdf_with_text_separated_tbl <- pdf_with_text_separated_tbl %>% 
  mutate(
    rank    = as.numeric(rank),
    streams = as.numeric(streams)
  )

pdf_with_text_separated_tbl
```

## 7. Finish things manually with __DataEditR__

This is the code I would use to start the DataEditR (inside of RStudio):

```{R, eval=FALSE}
pdf_with_text_final_tbl <- data_edit(pdf_with_text_separated_tbl)
```

You can then cut and paste the values as you would do in Excel.

![fig. 2 - DataEditR (before)](images/DataEditR_before.jpg)

When you're done editing, you should click the Refresh(?) button [1] and then Done [2].

![fig. 3 - DataEditR (after)](images/DataEditR_after.jpg)

We now have the _pdf_with_text_final_tbl_ to finally save as an Excel file:

```{R, include=FALSE}
path <- "index_files/pdf_with_text_final.csv"
pdf_with_text_final_tbl <- read_csv(file = path, locale = locale(encoding = "latin1")) %>% 
  select(-X1)
```
```{R}
pdf_with_text_final_tbl
```
Almost there! The data is now clean as a whistle and all that is left to do, at the moment, is to save it as an excel file.

## 8. Create Excel file with __writexl__

```{R}
write_xlsx(pdf_with_text_final_tbl, "index_files/excel_from_pdf_with_text.xlsx")
# You should change the file path to suit your needs
```

![fig. 4 - Extract from the final Excel file](images/excel_from_pdf_with_text.jpg)

# Outro

Beautiful, isn't it! It took us a while, but we got there eventually. Thanks for reading this far. If you're curious to see, how the same data behaves if it's in a table inside a PDF, tune in next week for part 2 of this PDF trilogy! Until then, happy text mining!

ps. I'm more than happy to chat about all things data. Just send me a message on LinkedIn if you wish to do so!